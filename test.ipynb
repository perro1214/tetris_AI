{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 22:41:32.688064: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-12 22:41:32.721758: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-12 22:41:32.722526: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-12 22:41:33.447654: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 22:41:37.776926: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 22:41:37.779504: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "層数: 1, データ量: 100, 精度: 0.391\n",
      "層数: 1, データ量: 1000, 精度: 0.843\n",
      "層数: 1, データ量: 10000, 精度: 0.938\n",
      "層数: 1, データ量: 60000, 精度: 0.974\n",
      "層数: 2, データ量: 100, 精度: 0.403\n",
      "層数: 2, データ量: 1000, 精度: 0.857\n",
      "層数: 2, データ量: 10000, 精度: 0.942\n",
      "層数: 2, データ量: 60000, 精度: 0.977\n",
      "層数: 3, データ量: 100, 精度: 0.313\n",
      "層数: 3, データ量: 1000, 精度: 0.848\n",
      "層数: 3, データ量: 10000, 精度: 0.945\n",
      "層数: 3, データ量: 60000, 精度: 0.976\n",
      "層数: 5, データ量: 100, 精度: 0.452\n",
      "層数: 5, データ量: 1000, 精度: 0.819\n",
      "層数: 5, データ量: 10000, 精度: 0.948\n",
      "層数: 5, データ量: 60000, 精度: 0.976\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# MNISTデータセットをロード\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 画像を正規化\n",
    "X_train = X_train.reshape((60000, 28, 28, 1)) / 255.0\n",
    "X_test = X_test.reshape((10000, 28, 28, 1)) / 255.0\n",
    "\n",
    "# ネットワークの層数を変化させる\n",
    "for layers in [1, 2, 3, 5]:\n",
    "    # モデルを構築\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(28, 28, 1)))\n",
    "    for _ in range(layers):\n",
    "        model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dense(10, activation=\"softmax\"))\n",
    "    model.compile(optimizer=Adam(), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    # データ量を変化させる\n",
    "    for n in [100, 1000, 10000, 60000]:\n",
    "        # モデルを学習\n",
    "        model.fit(X_train[:n], y_train[:n], epochs=5, batch_size=128, verbose=0)\n",
    "        \n",
    "        # テストデータで評価\n",
    "        _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        print(f\"層数: {layers}, データ量: {n}, 精度: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# 1. データの生成 (サンプルデータ)\n",
    "num_samples = 1000\n",
    "num_features = 220\n",
    "\n",
    "# 入力データ: 220次元の正規分布に従う乱数を1000サンプル生成\n",
    "X = np.random.randn(num_samples, num_features)\n",
    "# 目的変数: 2次元の正規分布に従う乱数を1000サンプル生成\n",
    "# 例として、出力1は入力の最初の100個の和 + ノイズ, 出力2は入力の最後の120個の和 + ノイズ\n",
    "pprint.pprint(len(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220 2\n"
     ]
    }
   ],
   "source": [
    "y = np.zeros((num_samples, 2))\n",
    "y[:, 0] = X[:, :100].sum(axis=1) + np.random.randn(num_samples) * 5  # ノイズを加える\n",
    "y[:, 1] = X[:, 100:].sum(axis=1) + np.random.randn(num_samples) * 5 # ノイズを加える\n",
    "\n",
    "# 2. データの分割 (訓練データとテストデータ)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(len(X_train[0]),len(y_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 137.4556 - mae: 9.4120 - val_loss: 139.6441 - val_mae: 9.2800\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.8898 - mae: 9.2091 - val_loss: 136.7129 - val_mae: 9.1761\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.3533 - mae: 8.8871 - val_loss: 127.9511 - val_mae: 8.8572\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 105.9692 - mae: 8.1969 - val_loss: 110.9703 - val_mae: 8.2180\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 78.6001 - mae: 6.9863 - val_loss: 86.9058 - val_mae: 7.2537\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 48.9708 - mae: 5.4505 - val_loss: 65.9575 - val_mae: 6.3060\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 28.7822 - mae: 4.2176 - val_loss: 53.3590 - val_mae: 5.7010\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 18.6692 - mae: 3.4058 - val_loss: 49.4448 - val_mae: 5.4785\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 13.1083 - mae: 2.8409 - val_loss: 46.8195 - val_mae: 5.3072\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 9.4714 - mae: 2.4212 - val_loss: 46.5960 - val_mae: 5.2922\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 7.0092 - mae: 2.0780 - val_loss: 45.7266 - val_mae: 5.2388\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5.1597 - mae: 1.7682 - val_loss: 45.2528 - val_mae: 5.2437\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3.9604 - mae: 1.5522 - val_loss: 46.0241 - val_mae: 5.3034\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2.8404 - mae: 1.2995 - val_loss: 46.1031 - val_mae: 5.2936\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.0983 - mae: 1.1132 - val_loss: 46.4278 - val_mae: 5.3452\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.5532 - mae: 0.9542 - val_loss: 46.5497 - val_mae: 5.3478\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.1643 - mae: 0.8110 - val_loss: 46.6115 - val_mae: 5.3675\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8255 - mae: 0.6841 - val_loss: 46.8570 - val_mae: 5.3838\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5967 - mae: 0.5751 - val_loss: 47.0907 - val_mae: 5.4042\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4323 - mae: 0.4827 - val_loss: 47.4795 - val_mae: 5.4344\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3121 - mae: 0.4022 - val_loss: 47.5704 - val_mae: 5.4467\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2294 - mae: 0.3427 - val_loss: 47.8463 - val_mae: 5.4616\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1678 - mae: 0.2874 - val_loss: 47.8395 - val_mae: 5.4688\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1195 - mae: 0.2375 - val_loss: 47.8247 - val_mae: 5.4694\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0888 - mae: 0.2013 - val_loss: 48.0365 - val_mae: 5.4820\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0635 - mae: 0.1654 - val_loss: 48.0225 - val_mae: 5.4852\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0463 - mae: 0.1358 - val_loss: 48.1802 - val_mae: 5.4934\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0349 - mae: 0.1147 - val_loss: 48.1321 - val_mae: 5.4929\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.0966 - val_loss: 48.1627 - val_mae: 5.4924\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0186 - mae: 0.0801 - val_loss: 48.2014 - val_mae: 5.4969\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0653 - val_loss: 48.2484 - val_mae: 5.4996\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0102 - mae: 0.0567 - val_loss: 48.2331 - val_mae: 5.4982\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0074 - mae: 0.0465 - val_loss: 48.2767 - val_mae: 5.5002\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0057 - mae: 0.0402 - val_loss: 48.2647 - val_mae: 5.5005\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0333 - val_loss: 48.2766 - val_mae: 5.4999\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0265 - val_loss: 48.3026 - val_mae: 5.5019\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0237 - val_loss: 48.3198 - val_mae: 5.5023\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0193 - val_loss: 48.3185 - val_mae: 5.5023\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0174 - val_loss: 48.3130 - val_mae: 5.5024\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 9.3224e-04 - mae: 0.0142 - val_loss: 48.3148 - val_mae: 5.5021\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 7.2597e-04 - mae: 0.0128 - val_loss: 48.3081 - val_mae: 5.5014\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 5.5531e-04 - mae: 0.0109 - val_loss: 48.3344 - val_mae: 5.5032\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4.0652e-04 - mae: 0.0090 - val_loss: 48.3215 - val_mae: 5.5026\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.0164e-04 - mae: 0.0074 - val_loss: 48.3362 - val_mae: 5.5033\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.2834e-04 - mae: 0.0065 - val_loss: 48.3370 - val_mae: 5.5036\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.7029e-04 - mae: 0.0056 - val_loss: 48.3394 - val_mae: 5.5036\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.3582e-04 - mae: 0.0051 - val_loss: 48.3359 - val_mae: 5.5036\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.0035e-04 - mae: 0.0045 - val_loss: 48.3467 - val_mae: 5.5041\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 8.2938e-05 - mae: 0.0044 - val_loss: 48.3408 - val_mae: 5.5039\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 6.0342e-05 - mae: 0.0038 - val_loss: 48.3457 - val_mae: 5.5039\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4.2453e-05 - mae: 0.0031 - val_loss: 48.3436 - val_mae: 5.5039\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.2395e-05 - mae: 0.0028 - val_loss: 48.3458 - val_mae: 5.5039\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.3301e-05 - mae: 0.0024 - val_loss: 48.3440 - val_mae: 5.5038\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.7563e-05 - mae: 0.0021 - val_loss: 48.3474 - val_mae: 5.5041\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.3619e-05 - mae: 0.0020 - val_loss: 48.3445 - val_mae: 5.5039\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.1699e-05 - mae: 0.0019 - val_loss: 48.3513 - val_mae: 5.5042\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 8.4792e-06 - mae: 0.0017 - val_loss: 48.3451 - val_mae: 5.5040\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 6.9636e-06 - mae: 0.0016 - val_loss: 48.3502 - val_mae: 5.5042\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 5.9391e-06 - mae: 0.0015 - val_loss: 48.3464 - val_mae: 5.5040\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 5.1043e-06 - mae: 0.0015 - val_loss: 48.3509 - val_mae: 5.5042\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 5.0111e-06 - mae: 0.0015 - val_loss: 48.3473 - val_mae: 5.5040\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 5.5338e-06 - mae: 0.0016 - val_loss: 48.3498 - val_mae: 5.5043\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 5.9027e-06 - mae: 0.0017 - val_loss: 48.3496 - val_mae: 5.5041\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 5.8872e-06 - mae: 0.0017 - val_loss: 48.3471 - val_mae: 5.5041\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 6.2226e-06 - mae: 0.0018 - val_loss: 48.3511 - val_mae: 5.5042\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 6.6887e-06 - mae: 0.0019 - val_loss: 48.3487 - val_mae: 5.5042\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 7.7355e-06 - mae: 0.0020 - val_loss: 48.3515 - val_mae: 5.5042\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 9.9304e-06 - mae: 0.0023 - val_loss: 48.3511 - val_mae: 5.5044\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.1453e-05 - mae: 0.0024 - val_loss: 48.3499 - val_mae: 5.5041\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.2394e-05 - mae: 0.0025 - val_loss: 48.3506 - val_mae: 5.5043\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.8452e-05 - mae: 0.0030 - val_loss: 48.3473 - val_mae: 5.5039\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.0222e-05 - mae: 0.0033 - val_loss: 48.3449 - val_mae: 5.5040\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.3654e-05 - mae: 0.0036 - val_loss: 48.3557 - val_mae: 5.5045\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4.0207e-05 - mae: 0.0045 - val_loss: 48.3531 - val_mae: 5.5044\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 5.8520e-05 - mae: 0.0055 - val_loss: 48.3421 - val_mae: 5.5037\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 7.8404e-05 - mae: 0.0064 - val_loss: 48.3590 - val_mae: 5.5047\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.0437e-04 - mae: 0.0076 - val_loss: 48.3488 - val_mae: 5.5041\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.8504e-04 - mae: 0.0101 - val_loss: 48.3582 - val_mae: 5.5043\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.1112e-04 - mae: 0.0129 - val_loss: 48.3514 - val_mae: 5.5037\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4.9228e-04 - mae: 0.0166 - val_loss: 48.3749 - val_mae: 5.5055\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7.7981e-04 - mae: 0.0208 - val_loss: 48.3229 - val_mae: 5.5025\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0264 - val_loss: 48.4013 - val_mae: 5.5087\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0348 - val_loss: 48.3331 - val_mae: 5.5017\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0495 - val_loss: 48.3701 - val_mae: 5.5065\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0676 - val_loss: 48.3733 - val_mae: 5.5020\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0215 - mae: 0.1027 - val_loss: 48.7038 - val_mae: 5.5211\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0384 - mae: 0.1413 - val_loss: 48.0983 - val_mae: 5.4975\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0705 - mae: 0.1970 - val_loss: 48.6524 - val_mae: 5.5061\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1131 - mae: 0.2491 - val_loss: 47.8876 - val_mae: 5.4949\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2365 - mae: 0.3521 - val_loss: 49.0017 - val_mae: 5.5147\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4287 - mae: 0.4816 - val_loss: 48.7002 - val_mae: 5.5320\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.9425 - mae: 0.6873 - val_loss: 48.2035 - val_mae: 5.4783\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.4493 - mae: 0.9268 - val_loss: 47.8042 - val_mae: 5.5117\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.9715 - mae: 1.0835 - val_loss: 47.2641 - val_mae: 5.4046\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.0444 - mae: 1.0748 - val_loss: 47.6475 - val_mae: 5.4332\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.5033 - mae: 0.9318 - val_loss: 48.0279 - val_mae: 5.5136\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.0590 - mae: 0.7862 - val_loss: 46.8666 - val_mae: 5.3973\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8772 - mae: 0.7031 - val_loss: 46.3417 - val_mae: 5.3861\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6406 - mae: 0.5947 - val_loss: 47.1459 - val_mae: 5.4363\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4467 - mae: 0.4916 - val_loss: 46.2317 - val_mae: 5.3981\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Mean Squared Error (MSE): 43.6291\n",
      "Mean Absolute Error (MAE): 5.3429\n",
      "R2 Score: 0.6865\n",
      "最初の5つの予測結果:\n",
      "予測: [9.435053  2.0547168], 実際: [11.11756608 -7.54237445]\n",
      "予測: [-6.3938885 17.155027 ], 実際: [-13.95651877  15.66919381]\n",
      "予測: [  2.6234941 -11.87131  ], 実際: [  6.04201842 -21.65223499]\n",
      "予測: [ -1.2521052 -15.068036 ], 実際: [-12.1635411  -10.08691239]\n",
      "予測: [-16.118303  -9.42025 ], 実際: [-21.74091571  -9.92502633]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 3. モデルの構築\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(64, activation=\"relu\", input_shape=(num_features,)),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(16, activation=\"relu\"),\n",
    "        layers.Dense(2),  # 出力層は2次元、活性化関数なし（線形関数）\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 4. モデルのコンパイル\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "# 5. モデルの学習\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1, verbose=1)\n",
    "\n",
    "# 6. モデルの評価\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 評価指標の計算\n",
    "mse = mean_squared_error(y_test, y_pred\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "\n",
    "# 7. (オプション) 予測結果の確認\n",
    "print(\"最初の5つの予測結果:\")\n",
    "for i in range(5):\n",
    "    print(f\"予測: {y_pred[i]}, 実際: {y_test[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
