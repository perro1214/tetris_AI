{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 02:51:58.756856: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-17 02:51:58.794787: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-17 02:51:58.795750: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-17 02:51:59.577242: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import pprint\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "print(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m現在のセルまたは前のセルでコードを実行中に、カーネル (Kernel) がクラッシュしました。\n",
      "\u001b[1;31mエラーの原因を特定するには、セル内のコードを確認してください。\n",
      "\u001b[1;31m詳細については<a href='https://aka.ms/vscodeJupyterKernelCrash'>こちら</a>をクリックします。\n",
      "\u001b[1;31m詳細については、Jupyter <a href='command:jupyter.viewOutput'>ログ</a> を参照してください。"
     ]
    }
   ],
   "source": [
    "with open('data.csv', 'r') as f:\n",
    "    lis = f.read().split()\n",
    "for i in range(len(lis)):\n",
    "    lis[i] = list(map(int,(lis[i].split(\",\"))))\n",
    "arr=np.array(lis)\n",
    "pprint.pprint(arr,width=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(467009, 227)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# 1. データの生成 (サンプルデータ)\n",
    "num_samples = arr.shape[0]\n",
    "num_features = arr.shape[1]\n",
    "\n",
    "# 入力データ: 220次元の正規分布に従う乱数を1000サンプル生成\n",
    "X = arr[:,:-3]\n",
    "y = arr[:,-3:]\n",
    "# 目的変数: 2次元の正規分布に従う乱数を1000サンプル生成\n",
    "# 例として、出力1は入力の最初の100個の和 + ノイズ, 出力2は入力の最後の120個の和 + ノイズ\n",
    "print(len(X[0]))\n",
    "print(len(y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224 3\n"
     ]
    }
   ],
   "source": [
    "# 2. データの分割 (訓練データとテストデータ)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(len(X_train[0]),len(y_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10508/10508 [==============================] - 25s 2ms/step - loss: 2.8018 - mae: 1.0552 - val_loss: 2.1565 - val_mae: 0.9430\n",
      "Epoch 2/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 2.0549 - mae: 0.9135 - val_loss: 2.0337 - val_mae: 0.9061\n",
      "Epoch 3/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.9443 - mae: 0.8748 - val_loss: 1.9419 - val_mae: 0.8652\n",
      "Epoch 4/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.8890 - mae: 0.8572 - val_loss: 1.9352 - val_mae: 0.8643\n",
      "Epoch 5/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.8519 - mae: 0.8442 - val_loss: 1.8928 - val_mae: 0.8470\n",
      "Epoch 6/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.8188 - mae: 0.8325 - val_loss: 1.9662 - val_mae: 0.8644\n",
      "Epoch 7/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.7982 - mae: 0.8243 - val_loss: 1.9003 - val_mae: 0.8573\n",
      "Epoch 8/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.7778 - mae: 0.8182 - val_loss: 1.8510 - val_mae: 0.8277\n",
      "Epoch 9/100\n",
      "10508/10508 [==============================] - 21s 2ms/step - loss: 1.7586 - mae: 0.8133 - val_loss: 1.8533 - val_mae: 0.8300\n",
      "Epoch 10/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.7461 - mae: 0.8100 - val_loss: 1.8682 - val_mae: 0.8336\n",
      "Epoch 11/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.7305 - mae: 0.8057 - val_loss: 1.8637 - val_mae: 0.8366\n",
      "Epoch 12/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.7179 - mae: 0.8026 - val_loss: 1.8526 - val_mae: 0.8376\n",
      "Epoch 13/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.7067 - mae: 0.7995 - val_loss: 1.8819 - val_mae: 0.8395\n",
      "Epoch 14/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.6979 - mae: 0.7966 - val_loss: 1.8308 - val_mae: 0.8115\n",
      "Epoch 15/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.6869 - mae: 0.7944 - val_loss: 1.8353 - val_mae: 0.8278\n",
      "Epoch 16/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.6799 - mae: 0.7922 - val_loss: 1.8450 - val_mae: 0.8246\n",
      "Epoch 17/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.6706 - mae: 0.7894 - val_loss: 1.8479 - val_mae: 0.8157\n",
      "Epoch 18/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.6658 - mae: 0.7882 - val_loss: 1.8448 - val_mae: 0.8160\n",
      "Epoch 19/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.6551 - mae: 0.7856 - val_loss: 1.8354 - val_mae: 0.8090\n",
      "Epoch 20/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.6522 - mae: 0.7847 - val_loss: 1.8371 - val_mae: 0.8139\n",
      "Epoch 21/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.6466 - mae: 0.7828 - val_loss: 1.8342 - val_mae: 0.8144\n",
      "Epoch 22/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.6367 - mae: 0.7801 - val_loss: 1.8563 - val_mae: 0.8199\n",
      "Epoch 23/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.6316 - mae: 0.7793 - val_loss: 1.8458 - val_mae: 0.8131\n",
      "Epoch 24/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.6276 - mae: 0.7779 - val_loss: 1.8341 - val_mae: 0.8143\n",
      "Epoch 25/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.6212 - mae: 0.7762 - val_loss: 1.8343 - val_mae: 0.8119\n",
      "Epoch 26/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.6160 - mae: 0.7752 - val_loss: 1.8495 - val_mae: 0.8292\n",
      "Epoch 27/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.6138 - mae: 0.7743 - val_loss: 1.8401 - val_mae: 0.8090\n",
      "Epoch 28/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.6074 - mae: 0.7729 - val_loss: 1.8315 - val_mae: 0.8086\n",
      "Epoch 29/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.6061 - mae: 0.7719 - val_loss: 1.8262 - val_mae: 0.8057\n",
      "Epoch 30/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.6038 - mae: 0.7711 - val_loss: 1.8112 - val_mae: 0.8061\n",
      "Epoch 31/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5988 - mae: 0.7706 - val_loss: 1.8281 - val_mae: 0.8030\n",
      "Epoch 32/100\n",
      "10508/10508 [==============================] - 23s 2ms/step - loss: 1.5926 - mae: 0.7691 - val_loss: 1.8466 - val_mae: 0.8061\n",
      "Epoch 33/100\n",
      "10508/10508 [==============================] - 19s 2ms/step - loss: 1.5918 - mae: 0.7685 - val_loss: 1.8269 - val_mae: 0.8022\n",
      "Epoch 34/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5888 - mae: 0.7680 - val_loss: 1.8487 - val_mae: 0.8070\n",
      "Epoch 35/100\n",
      "10508/10508 [==============================] - 19s 2ms/step - loss: 1.5852 - mae: 0.7667 - val_loss: 1.8370 - val_mae: 0.8026\n",
      "Epoch 36/100\n",
      "10508/10508 [==============================] - 22s 2ms/step - loss: 1.5806 - mae: 0.7658 - val_loss: 1.8320 - val_mae: 0.8027\n",
      "Epoch 37/100\n",
      "10508/10508 [==============================] - 31s 3ms/step - loss: 1.5811 - mae: 0.7654 - val_loss: 1.8646 - val_mae: 0.8238\n",
      "Epoch 38/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5759 - mae: 0.7648 - val_loss: 1.8489 - val_mae: 0.8072\n",
      "Epoch 39/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5733 - mae: 0.7643 - val_loss: 1.8320 - val_mae: 0.8063\n",
      "Epoch 40/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5704 - mae: 0.7630 - val_loss: 1.8552 - val_mae: 0.8034\n",
      "Epoch 41/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5748 - mae: 0.7628 - val_loss: 1.8398 - val_mae: 0.8074\n",
      "Epoch 42/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5646 - mae: 0.7616 - val_loss: 1.8344 - val_mae: 0.8039\n",
      "Epoch 43/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5637 - mae: 0.7616 - val_loss: 1.8511 - val_mae: 0.8286\n",
      "Epoch 44/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5615 - mae: 0.7606 - val_loss: 1.8317 - val_mae: 0.8053\n",
      "Epoch 45/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5595 - mae: 0.7606 - val_loss: 1.8363 - val_mae: 0.8076\n",
      "Epoch 46/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5586 - mae: 0.7603 - val_loss: 1.8549 - val_mae: 0.8129\n",
      "Epoch 47/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5540 - mae: 0.7595 - val_loss: 1.8550 - val_mae: 0.8052\n",
      "Epoch 48/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5526 - mae: 0.7590 - val_loss: 1.8455 - val_mae: 0.8133\n",
      "Epoch 49/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5525 - mae: 0.7585 - val_loss: 1.8460 - val_mae: 0.8030\n",
      "Epoch 50/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5503 - mae: 0.7582 - val_loss: 1.8604 - val_mae: 0.8108\n",
      "Epoch 51/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5485 - mae: 0.7578 - val_loss: 1.8437 - val_mae: 0.8054\n",
      "Epoch 52/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5451 - mae: 0.7568 - val_loss: 1.8529 - val_mae: 0.8102\n",
      "Epoch 53/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5428 - mae: 0.7560 - val_loss: 1.8511 - val_mae: 0.8104\n",
      "Epoch 54/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5413 - mae: 0.7558 - val_loss: 1.8668 - val_mae: 0.8095\n",
      "Epoch 55/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5394 - mae: 0.7553 - val_loss: 1.8300 - val_mae: 0.8082\n",
      "Epoch 56/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5382 - mae: 0.7557 - val_loss: 1.8510 - val_mae: 0.8125\n",
      "Epoch 57/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5351 - mae: 0.7548 - val_loss: 1.8460 - val_mae: 0.8136\n",
      "Epoch 58/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5341 - mae: 0.7542 - val_loss: 1.8591 - val_mae: 0.8107\n",
      "Epoch 59/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5337 - mae: 0.7543 - val_loss: 1.8411 - val_mae: 0.8134\n",
      "Epoch 60/100\n",
      "10508/10508 [==============================] - 21s 2ms/step - loss: 1.5309 - mae: 0.7534 - val_loss: 1.8676 - val_mae: 0.8102\n",
      "Epoch 61/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5296 - mae: 0.7529 - val_loss: 1.8628 - val_mae: 0.8129\n",
      "Epoch 62/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5280 - mae: 0.7526 - val_loss: 1.8499 - val_mae: 0.8019\n",
      "Epoch 63/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5266 - mae: 0.7525 - val_loss: 1.8866 - val_mae: 0.8249\n",
      "Epoch 64/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5250 - mae: 0.7518 - val_loss: 1.8654 - val_mae: 0.8091\n",
      "Epoch 65/100\n",
      "10508/10508 [==============================] - 21s 2ms/step - loss: 1.5226 - mae: 0.7514 - val_loss: 1.8516 - val_mae: 0.8010\n",
      "Epoch 66/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5209 - mae: 0.7506 - val_loss: 1.8819 - val_mae: 0.8173\n",
      "Epoch 67/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5215 - mae: 0.7508 - val_loss: 1.8783 - val_mae: 0.8135\n",
      "Epoch 68/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5192 - mae: 0.7502 - val_loss: 1.8610 - val_mae: 0.8074\n",
      "Epoch 69/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5173 - mae: 0.7500 - val_loss: 1.8726 - val_mae: 0.8110\n",
      "Epoch 70/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5153 - mae: 0.7494 - val_loss: 1.8625 - val_mae: 0.8059\n",
      "Epoch 71/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5158 - mae: 0.7493 - val_loss: 1.8606 - val_mae: 0.8125\n",
      "Epoch 72/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5127 - mae: 0.7490 - val_loss: 1.8854 - val_mae: 0.8190\n",
      "Epoch 73/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5132 - mae: 0.7488 - val_loss: 1.8701 - val_mae: 0.8049\n",
      "Epoch 74/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5102 - mae: 0.7480 - val_loss: 1.8623 - val_mae: 0.8093\n",
      "Epoch 75/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5100 - mae: 0.7478 - val_loss: 1.8545 - val_mae: 0.8059\n",
      "Epoch 76/100\n",
      "10508/10508 [==============================] - 21s 2ms/step - loss: 1.5082 - mae: 0.7475 - val_loss: 1.8685 - val_mae: 0.8063\n",
      "Epoch 77/100\n",
      "10508/10508 [==============================] - 24s 2ms/step - loss: 1.5074 - mae: 0.7472 - val_loss: 1.9043 - val_mae: 0.8149\n",
      "Epoch 78/100\n",
      "10508/10508 [==============================] - 22s 2ms/step - loss: 1.5064 - mae: 0.7468 - val_loss: 1.8758 - val_mae: 0.8054\n",
      "Epoch 79/100\n",
      "10508/10508 [==============================] - 21s 2ms/step - loss: 1.5079 - mae: 0.7472 - val_loss: 1.8755 - val_mae: 0.8113\n",
      "Epoch 80/100\n",
      "10508/10508 [==============================] - 22s 2ms/step - loss: 1.5021 - mae: 0.7460 - val_loss: 1.8750 - val_mae: 0.8021\n",
      "Epoch 81/100\n",
      "10508/10508 [==============================] - 22s 2ms/step - loss: 1.5033 - mae: 0.7461 - val_loss: 1.8628 - val_mae: 0.8027\n",
      "Epoch 82/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5026 - mae: 0.7459 - val_loss: 1.8728 - val_mae: 0.8178\n",
      "Epoch 83/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.5010 - mae: 0.7458 - val_loss: 1.8800 - val_mae: 0.8028\n",
      "Epoch 84/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.4979 - mae: 0.7448 - val_loss: 1.8791 - val_mae: 0.8075\n",
      "Epoch 85/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.4986 - mae: 0.7447 - val_loss: 1.8743 - val_mae: 0.8160\n",
      "Epoch 86/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.4970 - mae: 0.7445 - val_loss: 1.8816 - val_mae: 0.8137\n",
      "Epoch 87/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.4938 - mae: 0.7440 - val_loss: 1.8638 - val_mae: 0.8055\n",
      "Epoch 88/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.4948 - mae: 0.7439 - val_loss: 1.8770 - val_mae: 0.8063\n",
      "Epoch 89/100\n",
      "10508/10508 [==============================] - 21s 2ms/step - loss: 1.4958 - mae: 0.7439 - val_loss: 1.8693 - val_mae: 0.8131\n",
      "Epoch 90/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.4961 - mae: 0.7439 - val_loss: 1.8954 - val_mae: 0.8140\n",
      "Epoch 91/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.4937 - mae: 0.7437 - val_loss: 1.8663 - val_mae: 0.8119\n",
      "Epoch 92/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.4895 - mae: 0.7427 - val_loss: 1.8648 - val_mae: 0.8060\n",
      "Epoch 93/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.4904 - mae: 0.7428 - val_loss: 1.8834 - val_mae: 0.8109\n",
      "Epoch 94/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.4895 - mae: 0.7423 - val_loss: 1.8904 - val_mae: 0.8076\n",
      "Epoch 95/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.4895 - mae: 0.7425 - val_loss: 1.8920 - val_mae: 0.8091\n",
      "Epoch 96/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.4875 - mae: 0.7421 - val_loss: 1.8780 - val_mae: 0.8067\n",
      "Epoch 97/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.4874 - mae: 0.7418 - val_loss: 1.8933 - val_mae: 0.8111\n",
      "Epoch 98/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.4863 - mae: 0.7415 - val_loss: 1.8937 - val_mae: 0.8186\n",
      "Epoch 99/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.4878 - mae: 0.7419 - val_loss: 1.8808 - val_mae: 0.8087\n",
      "Epoch 100/100\n",
      "10508/10508 [==============================] - 20s 2ms/step - loss: 1.4850 - mae: 0.7412 - val_loss: 1.8969 - val_mae: 0.8108\n",
      "2919/2919 [==============================] - 3s 1ms/step\n",
      "Mean Squared Error (MSE): 1.8782\n",
      "Mean Absolute Error (MAE): 0.8065\n",
      "R2 Score: 0.3093\n",
      "最初の5つの予測結果:\n",
      "予測: [9.3481503e+00 1.0148934e-03 4.3107424e+00], 実際: [8 0 6]\n",
      "予測: [7.7390628e+00 2.2695819e-04 3.9137411e+00], 実際: [7 0 7]\n",
      "予測: [2.5660882e+00 2.1685208e-03 5.6266742e+00], 実際: [3 0 1]\n",
      "予測: [8.6203852e+00 7.5172167e-04 4.1062446e+00], 実際: [9 0 7]\n",
      "予測: [1.8996326e+01 9.8523684e-03 3.9067328e+00], 実際: [17  0  7]\n"
     ]
    }
   ],
   "source": [
    "# 3. モデルの構築\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(128, activation=\"relu\", input_shape=(224,)),  # ここを修正\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(16, activation=\"relu\"),\n",
    "        layers.Dense(3),\n",
    "    ]\n",
    ")\n",
    "# 4. モデルのコンパイル\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "# 5. モデルの学習\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1, verbose=1)\n",
    "\n",
    "# 6. モデルの評価\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 評価指標の計算\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "\n",
    "# 7. (オプション) 予測結果の確認\n",
    "print(\"最初の5つの予測結果:\")\n",
    "for i in range(5):\n",
    "    print(f\"予測: {y_pred[i]}, 実際: {y_test[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最初の5つの予測結果:\n",
      "予測: 9.348, 実際: 8.000\n",
      "予測: 7.739, 実際: 7.000\n",
      "予測: 2.566, 実際: 3.000\n",
      "予測: 8.620, 実際: 9.000\n",
      "予測: 18.996, 実際: 17.000\n"
     ]
    }
   ],
   "source": [
    "print(\"最初の5つの予測結果:\")\n",
    "for i in range(5):\n",
    "    print(\"予測: {:.3f}, 実際: {:.3f}\".format(y_pred[i][0],y_test[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m argv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28minput\u001b[39m())\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_gen/model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "argv = int(input())\n",
    "model.save(f\"model_gen/model_{argv}.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
